{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7a9f9cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(sdp-term) C:\\Pythontemp\\TUKorea\\sdp\\term-project>conda.bat activate sdp-term \n"
     ]
    }
   ],
   "source": [
    "!activate sdp-term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.6.0'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.6.0'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "keras.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "'1.13.0'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.get_device_name(0)\n",
    "torch.cuda.is_available()\n",
    "torch.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "614ccc2a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from seed import seed_everything\n",
    "from customdataset import *\n",
    "from depthmodel import depthmodel\n",
    "from train import train, casetrain\n",
    "from inference import inference\n",
    "from casemodel import Casemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4b68a7a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %% datasets path\n",
    "CASE_BEST_MODEL_PATH = 'datasets/case_best_model.pth'\n",
    "BEST_MODEL1_PATH = 'datasets/best_model1.pth'\n",
    "BEST_MODEL2_PATH = 'datasets/best_model2.pth'\n",
    "BEST_MODEL3_PATH = 'datasets/best_model3.pth'\n",
    "BEST_MODEL4_PATH = 'datasets/best_model4.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "892612f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "504319ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# %% device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8260d2fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%CFG\n",
    "CFG = {\n",
    "    'WIDTH': 48,\n",
    "    'HEIGHT': 72,\n",
    "    'EPOCHS': 40,\n",
    "    'LEARNING_RATE': 1e-7,\n",
    "    'CASE_LEARNING_RATE': 1e-4,\n",
    "    'CASE_EPOCHS': 60,\n",
    "    'BATCH_SIZE': 64,\n",
    "    'SEED': 44\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c65a220",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%Random seed\n",
    "seed_everything(CFG['SEED'])  # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91c17ee7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "depthmodel(\n  (fc1): Sequential(\n    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=1, ceil_mode=False)\n    (3): ReLU()\n  )\n  (yp1): Sequential(\n    (0): Conv2d(64, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (xp1): Sequential(\n    (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU()\n    (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (green1): Sequential(\n    (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU()\n    (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (yp2): Sequential(\n    (0): Conv2d(256, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (1): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=1, ceil_mode=False)\n    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (xp2): Sequential(\n    (0): Conv2d(256, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (1): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=1, ceil_mode=False)\n    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): ReLU()\n    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): ReLU()\n    (7): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n    (8): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (green2): Sequential(\n    (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU()\n    (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (yp3): Sequential(\n    (0): Conv2d(512, 1024, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (1): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=1, ceil_mode=False)\n    (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (xp3): Sequential(\n    (0): Conv2d(512, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (1): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=1, ceil_mode=False)\n    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): ReLU()\n    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): ReLU()\n    (7): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n    (8): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (green3): Sequential(\n    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU()\n    (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n    (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (fc2): Sequential(\n    (0): Conv2d(1024, 516, kernel_size=(1, 1), stride=(1, 1))\n    (1): BatchNorm2d(516, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (upconv1): Sequential(\n    (0): Upsample(scale_factor=2.0, mode=nearest)\n    (1): Conv2d(516, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): ReLU()\n  )\n  (upconv2): Sequential(\n    (0): Upsample(scale_factor=2.0, mode=nearest)\n    (1): Conv2d(256, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): ReLU()\n  )\n  (upconv3): Sequential(\n    (0): Upsample(scale_factor=2.0, mode=nearest)\n    (1): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): ReLU()\n  )\n  (fc3): Sequential(\n    (0): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n  )\n  (relu): ReLU(inplace=True)\n)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%model setting\n",
    "case_model = Casemodel()\n",
    "case_model = case_model.to(device)\n",
    "case_model.eval()\n",
    "\n",
    "model1 = depthmodel()\n",
    "model1 = model1.to(device)\n",
    "model1.eval()\n",
    "\n",
    "model2 = depthmodel()\n",
    "model2 = model2.to(device)\n",
    "model2.eval()\n",
    "\n",
    "model3 = depthmodel()\n",
    "model3 = model3.to(device)\n",
    "model3.eval()\n",
    "\n",
    "model4 = depthmodel()\n",
    "model4 = model4.to(device)\n",
    "model4.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "862189a8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%parameters setting\n",
    "optimizer1 = torch.optim.Adam(params=model1.parameters(), lr=CFG[\"LEARNING_RATE\"], weight_decay=0.00001)\n",
    "optimizer2 = torch.optim.Adam(params=model2.parameters(), lr=CFG[\"LEARNING_RATE\"], weight_decay=0.00001)\n",
    "optimizer3 = torch.optim.Adam(params=model3.parameters(), lr=CFG[\"LEARNING_RATE\"], weight_decay=0.00001)\n",
    "optimizer4 = torch.optim.Adam(params=model4.parameters(), lr=CFG[\"LEARNING_RATE\"], weight_decay=0.00001)\n",
    "\n",
    "case_optimizer = torch.optim.Adam(params=case_model.parameters(), lr=CFG[\"CASE_LEARNING_RATE\"], weight_decay=0.00001)\n",
    "case_criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7124ce03",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "case_checkpoint = torch.load(CASE_BEST_MODEL_PATH)\n",
    "case_model = Casemodel()\n",
    "case_model = case_model.to(device)\n",
    "case_model.load_state_dict(case_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "761e6960",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 854/854 [05:50<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Train loss: 1.4953940952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:42<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vail set: Loss: 1.4917, Accuracy: 1509/6067 ( 25%)\n",
      "\n",
      "Model Saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 854/854 [05:06<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] Train loss: 1.4953515809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:34<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vail set: Loss: 1.4916, Accuracy: 1509/6067 ( 25%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 854/854 [04:49<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] Train loss: 1.4948155340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:32<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vail set: Loss: 1.4916, Accuracy: 1509/6067 ( 25%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 854/854 [05:16<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] Train loss: 1.4952813051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:31<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vail set: Loss: 1.4917, Accuracy: 1509/6067 ( 25%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 854/854 [04:57<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] Train loss: 1.4947825186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:34<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vail set: Loss: 1.4914, Accuracy: 1509/6067 ( 25%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 854/854 [05:05<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6] Train loss: 1.4953851281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:32<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vail set: Loss: 1.4918, Accuracy: 1509/6067 ( 25%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 854/854 [06:18<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7] Train loss: 1.4950976895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:34<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vail set: Loss: 1.4919, Accuracy: 1509/6067 ( 25%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 854/854 [05:09<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8] Train loss: 1.4953651973\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [21], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# %%\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m best_acc, best_epoch, vali_acc, val_loss, tr_loss \u001B[38;5;241m=\u001B[39m \u001B[43mcasetrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcase_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcase_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcase_criterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m                                                              \u001B[49m\u001B[43mcase_train_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcase_validation_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m                                                              \u001B[49m\u001B[43mCFG\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mCASE_EPOCHS\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Pythontemp\\TUKorea\\sdp\\term-project\\train.py:131\u001B[0m, in \u001B[0;36mcasetrain\u001B[1;34m(model, optimizer, criterion, train_loader, val_loader, epochs, scheduler, device, bestacc)\u001B[0m\n\u001B[0;32m    128\u001B[0m correct \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    130\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():  \u001B[38;5;66;03m# 파라미터 업데이트 안하기 때문에 no_grad 사용\u001B[39;00m\n\u001B[1;32m--> 131\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m img, label \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m)\u001B[49m):\n\u001B[0;32m    132\u001B[0m         img, label \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mto(device), label\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m    134\u001B[0m         logit \u001B[38;5;241m=\u001B[39m model(img)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sdp-term\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:435\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    433\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[0;32m    434\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 435\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sdp-term\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:381\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    379\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    380\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[1;32m--> 381\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sdp-term\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1034\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m   1027\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1028\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[0;32m   1029\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[0;32m   1030\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[0;32m   1031\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[0;32m   1032\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[0;32m   1033\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[1;32m-> 1034\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1035\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[0;32m   1036\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sdp-term\\lib\\multiprocessing\\process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[0;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    120\u001B[0m _cleanup()\n\u001B[1;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sdp-term\\lib\\multiprocessing\\context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sdp-term\\lib\\multiprocessing\\context.py:327\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    324\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m    326\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_win32\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[1;32m--> 327\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sdp-term\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     92\u001B[0m     reduction\u001B[38;5;241m.\u001B[39mdump(prep_data, to_child)\n\u001B[1;32m---> 93\u001B[0m     \u001B[43mreduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_child\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     95\u001B[0m     set_spawning_popen(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sdp-term\\lib\\multiprocessing\\reduction.py:60\u001B[0m, in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdump\u001B[39m(obj, file, protocol\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     59\u001B[0m     \u001B[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m     \u001B[43mForkingPickler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# %%\n",
    "best_acc, best_epoch, vali_acc, val_loss, tr_loss = casetrain(case_model, case_optimizer, case_criterion,\n",
    "                                                              case_train_loader, case_validation_loader,\n",
    "                                                              CFG['CASE_EPOCHS'], scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62764464",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %% visible result\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.plot(tr_loss[:], label='train loss')\n",
    "plt.plot(val_loss[:], label='validation loss')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ba0fe6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "checkpoint = torch.load(BEST_MODEL1_PATH)\n",
    "model1 = depthmodel()\n",
    "model1 = model1.to(device)\n",
    "model1.load_state_dict(checkpoint)\n",
    "\n",
    "checkpoint = torch.load(BEST_MODEL2_PATH)\n",
    "model2 = depthmodel()\n",
    "model2 = model2.to(device)\n",
    "model2.load_state_dict(checkpoint)\n",
    "\n",
    "checkpoint = torch.load(BEST_MODEL3_PATH)\n",
    "model3 = depthmodel()\n",
    "model3 = model3.to(device)\n",
    "model3.load_state_dict(checkpoint)\n",
    "\n",
    "checkpoint = torch.load(BEST_MODEL4_PATH)\n",
    "model4 = depthmodel()\n",
    "model4 = model4.to(device)\n",
    "model4.load_state_dict(checkpoint)\n",
    "\n",
    "case_checkpoint = torch.load(CASE_BEST_MODEL_PATH)\n",
    "case_model = Casemodel()\n",
    "case_model = case_model.to(device)\n",
    "case_model.load_state_dict(case_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe27f690",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %% each train\n",
    "# train first time\n",
    "train_loss, validation_loss, best_loss, epochs = train(model1, 1, optimizer1, train_loader1, val_loader1, scheduler,\n",
    "                                                       device, CFG['EPOCHS'])\n",
    "train_loss, validation_loss, best_loss, epochs = train(model2, 2, optimizer2, train_loader2, val_loader2, scheduler,\n",
    "                                                       device, CFG['EPOCHS'])\n",
    "train_loss, validation_loss, best_loss, epochs = train(model3, 3, optimizer3, train_loader3, val_loader3, scheduler,\n",
    "                                                       device, CFG['EPOCHS'])\n",
    "train_loss, validation_loss, best_loss, epochs = train(model4, 4, optimizer4, train_loader4, val_loader4, scheduler,\n",
    "                                                       device, CFG['EPOCHS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706f2020",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %% visible result\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.plot(train_loss[:], label='train loss')\n",
    "plt.plot(validation_loss[:], label='validation loss')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ea3b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %% get best models\n",
    "checkpoint = torch.load(BEST_MODEL1_PATH)\n",
    "model1 = depthmodel()\n",
    "model1 = model1.to(device)\n",
    "model1.load_state_dict(checkpoint)\n",
    "\n",
    "checkpoint = torch.load(BEST_MODEL2_PATH)\n",
    "model2 = depthmodel()\n",
    "model2 = model2.to(device)\n",
    "model2.load_state_dict(checkpoint)\n",
    "\n",
    "checkpoint = torch.load(BEST_MODEL3_PATH)\n",
    "model3 = depthmodel()\n",
    "model3 = model3.to(device)\n",
    "model3.load_state_dict(checkpoint)\n",
    "\n",
    "checkpoint = torch.load(BEST_MODEL4_PATH)\n",
    "model4 = depthmodel()\n",
    "model4 = model4.to(device)\n",
    "model4.load_state_dict(checkpoint)\n",
    "\n",
    "case_checkpoint = torch.load(CASE_BEST_MODEL_PATH)\n",
    "case_model = Casemodel()\n",
    "case_model = case_model.to(device)\n",
    "case_model.load_state_dict(case_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d361f74",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %% submit\n",
    "inference(model1, model2, model3, model4, case_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd920a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %% summary\n",
    "\"\"\"\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(1, CFG['WIDTH'], CFG['HEIGHT']), device=device.type)\n",
    "\n",
    "print(model)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}