{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7a9f9cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(jupyter) C:\\PythonTemp\\TUKorea\\sdp\\term-project>conda.bat activate jupyter \n"
     ]
    }
   ],
   "source": [
    "!activate jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "614ccc2a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Instance and class checks can only be used with @runtime_checkable protocols",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [28], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mseed\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m seed_everything\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcustomdataset\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdepthmodel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m depthmodel\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtrain\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train, casetrain\n",
      "File \u001B[1;32mC:\\PythonTemp\\TUKorea\\sdp\\term-project\\customdataset.py:136\u001B[0m\n\u001B[0;32m    134\u001B[0m \u001B[38;5;66;03m# %%make dataset\u001B[39;00m\n\u001B[0;32m    135\u001B[0m train_dataset1 \u001B[38;5;241m=\u001B[39m CustomDataset(train_sem_paths1, train_depth_paths1)\n\u001B[1;32m--> 136\u001B[0m train_loader1 \u001B[38;5;241m=\u001B[39m \u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    138\u001B[0m val_dataset1 \u001B[38;5;241m=\u001B[39m CustomDataset(val_sem_paths1, val_depth_paths1)\n\u001B[0;32m    139\u001B[0m val_loader1 \u001B[38;5;241m=\u001B[39m DataLoader(val_dataset1, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\jupyter\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:200\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001B[0m\n\u001B[0;32m    194\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmultiprocessing_context \u001B[38;5;241m=\u001B[39m multiprocessing_context\n\u001B[0;32m    196\u001B[0m \u001B[38;5;66;03m# Arg-check dataset related before checking samplers because we want to\u001B[39;00m\n\u001B[0;32m    197\u001B[0m \u001B[38;5;66;03m# tell users that iterable-style datasets are incompatible with custom\u001B[39;00m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;66;03m# samplers first, so that they don't learn that this combo doesn't work\u001B[39;00m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;66;03m# after spending time fixing the custom sampler errors.\u001B[39;00m\n\u001B[1;32m--> 200\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterableDataset\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m=\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    202\u001B[0m     \u001B[38;5;66;03m# NOTE [ Custom Samplers and IterableDataset ]\u001B[39;00m\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m    204\u001B[0m     \u001B[38;5;66;03m# `IterableDataset` does not support custom `batch_sampler` or\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    225\u001B[0m     \u001B[38;5;66;03m# this, and support custom samplers that specify the assignments to\u001B[39;00m\n\u001B[0;32m    226\u001B[0m     \u001B[38;5;66;03m# specific workers.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\jupyter\\lib\\typing.py:1498\u001B[0m, in \u001B[0;36m_ProtocolMeta.__instancecheck__\u001B[1;34m(cls, instance)\u001B[0m\n\u001B[0;32m   1490\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__instancecheck__\u001B[39m(\u001B[38;5;28mcls\u001B[39m, instance):\n\u001B[0;32m   1491\u001B[0m     \u001B[38;5;66;03m# We need this method for situations where attributes are\u001B[39;00m\n\u001B[0;32m   1492\u001B[0m     \u001B[38;5;66;03m# assigned in __init__.\u001B[39;00m\n\u001B[0;32m   1493\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1494\u001B[0m         \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_is_protocol\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[0;32m   1495\u001B[0m         \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_is_runtime_protocol\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[0;32m   1496\u001B[0m         \u001B[38;5;129;01mnot\u001B[39;00m _allow_reckless_class_checks(depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m   1497\u001B[0m     ):\n\u001B[1;32m-> 1498\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInstance and class checks can only be used with\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1499\u001B[0m                         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m @runtime_checkable protocols\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1501\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_is_protocol\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1502\u001B[0m             _is_callable_members_only(\u001B[38;5;28mcls\u001B[39m)) \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m             \u001B[38;5;28missubclass\u001B[39m(instance\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m, \u001B[38;5;28mcls\u001B[39m)):\n\u001B[0;32m   1504\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: Instance and class checks can only be used with @runtime_checkable protocols"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from seed import seed_everything\n",
    "from customdataset import *\n",
    "from depthmodel import depthmodel\n",
    "from train import train, casetrain\n",
    "from inference import inference\n",
    "from casemodel import Casemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4b68a7a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %% datasets path\n",
    "CASE_BEST_MODEL_PATH = 'datasets/case_best_model.pth'\n",
    "BEST_MODEL1_PATH = 'datasets/best_model1.pth'\n",
    "BEST_MODEL2_PATH = 'datasets/best_model2.pth'\n",
    "BEST_MODEL3_PATH = 'datasets/best_model3.pth'\n",
    "BEST_MODEL4_PATH = 'datasets/best_model4.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "892612f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "504319ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# %% device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8260d2fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%CFG\n",
    "CFG = {\n",
    "    'WIDTH': 48,\n",
    "    'HEIGHT': 72,\n",
    "    'EPOCHS': 40,\n",
    "    'LEARNING_RATE': 1e-7,\n",
    "    'CASE_LEARNING_RATE': 1e-4,\n",
    "    'CASE_EPOCHS': 60,\n",
    "    'BATCH_SIZE': 64,\n",
    "    'SEED': 44\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c65a220",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%Random seed\n",
    "seed_everything(CFG['SEED'])  # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91c17ee7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Casemodel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [26], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# %%model setting\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m case_model \u001B[38;5;241m=\u001B[39m \u001B[43mCasemodel\u001B[49m()\n\u001B[0;32m      3\u001B[0m case_model \u001B[38;5;241m=\u001B[39m case_model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m      4\u001B[0m case_model\u001B[38;5;241m.\u001B[39meval()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'Casemodel' is not defined"
     ]
    }
   ],
   "source": [
    "# %%model setting\n",
    "case_model = Casemodel()\n",
    "case_model = case_model.to(device)\n",
    "case_model.eval()\n",
    "\n",
    "model1 = depthmodel()\n",
    "model1 = model1.to(device)\n",
    "model1.eval()\n",
    "\n",
    "model2 = depthmodel()\n",
    "model2 = model2.to(device)\n",
    "model2.eval()\n",
    "\n",
    "model3 = depthmodel()\n",
    "model3 = model3.to(device)\n",
    "model3.eval()\n",
    "\n",
    "model4 = depthmodel()\n",
    "model4 = model4.to(device)\n",
    "model4.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "862189a8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [25], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# %%parameters setting\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m optimizer1 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(params\u001B[38;5;241m=\u001B[39m\u001B[43mmodel1\u001B[49m\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mCFG[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLEARNING_RATE\u001B[39m\u001B[38;5;124m\"\u001B[39m], weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.00001\u001B[39m)\n\u001B[0;32m      3\u001B[0m optimizer2 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(params\u001B[38;5;241m=\u001B[39mmodel2\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mCFG[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLEARNING_RATE\u001B[39m\u001B[38;5;124m\"\u001B[39m], weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.00001\u001B[39m)\n\u001B[0;32m      4\u001B[0m optimizer3 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(params\u001B[38;5;241m=\u001B[39mmodel3\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mCFG[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLEARNING_RATE\u001B[39m\u001B[38;5;124m\"\u001B[39m], weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.00001\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model1' is not defined"
     ]
    }
   ],
   "source": [
    "# %%parameters setting\n",
    "optimizer1 = torch.optim.Adam(params=model1.parameters(), lr=CFG[\"LEARNING_RATE\"], weight_decay=0.00001)\n",
    "optimizer2 = torch.optim.Adam(params=model2.parameters(), lr=CFG[\"LEARNING_RATE\"], weight_decay=0.00001)\n",
    "optimizer3 = torch.optim.Adam(params=model3.parameters(), lr=CFG[\"LEARNING_RATE\"], weight_decay=0.00001)\n",
    "optimizer4 = torch.optim.Adam(params=model4.parameters(), lr=CFG[\"LEARNING_RATE\"], weight_decay=0.00001)\n",
    "\n",
    "case_optimizer = torch.optim.Adam(params=case_model.parameters(), lr=CFG[\"CASE_LEARNING_RATE\"], weight_decay=0.00001)\n",
    "case_criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7124ce03",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "case_checkpoint = torch.load(CASE_BEST_MODEL_PATH)\n",
    "case_model = casemodel()\n",
    "case_model = case_model.to(device)\n",
    "case_model.load_state_dict(case_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761e6960",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "best_acc, best_epoch, vali_acc, val_loss, tr_loss = casetrain(case_model, case_optimizer, case_criterion,\n",
    "                                                              case_train_loader, case_validation_loader,\n",
    "                                                              CFG['CASE_EPOCHS'], scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62764464",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %% visible result\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.plot(tr_loss[:], label='train loss')\n",
    "plt.plot(val_loss[:], label='validation loss')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ba0fe6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "checkpoint = torch.load(BEST_MODEL1_PATH)\n",
    "model1 = depthmodel()\n",
    "model1 = model1.to(device)\n",
    "model1.load_state_dict(checkpoint)\n",
    "\n",
    "checkpoint = torch.load(BEST_MODEL2_PATH)\n",
    "model2 = depthmodel()\n",
    "model2 = model2.to(device)\n",
    "model2.load_state_dict(checkpoint)\n",
    "\n",
    "checkpoint = torch.load(BEST_MODEL3_PATH)\n",
    "model3 = depthmodel()\n",
    "model3 = model3.to(device)\n",
    "model3.load_state_dict(checkpoint)\n",
    "\n",
    "checkpoint = torch.load(BEST_MODEL4_PATH)\n",
    "model4 = depthmodel()\n",
    "model4 = model4.to(device)\n",
    "model4.load_state_dict(checkpoint)\n",
    "\n",
    "case_checkpoint = torch.load(CASE_BEST_MODEL_PATH)\n",
    "case_model = casemodel()\n",
    "case_model = case_model.to(device)\n",
    "case_model.load_state_dict(case_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe27f690",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %% each train\n",
    "# train first time\n",
    "train_loss, validation_loss, best_loss, epochs = train(model1, 1, optimizer1, train_loader1, val_loader1, scheduler,\n",
    "                                                       device, CFG['EPOCHS'])\n",
    "train_loss, validation_loss, best_loss, epochs = train(model2, 2, optimizer2, train_loader2, val_loader2, scheduler,\n",
    "                                                       device, CFG['EPOCHS'])\n",
    "train_loss, validation_loss, best_loss, epochs = train(model3, 3, optimizer3, train_loader3, val_loader3, scheduler,\n",
    "                                                       device, CFG['EPOCHS'])\n",
    "train_loss, validation_loss, best_loss, epochs = train(model4, 4, optimizer4, train_loader4, val_loader4, scheduler,\n",
    "                                                       device, CFG['EPOCHS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706f2020",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %% visible result\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.plot(train_loss[:], label='train loss')\n",
    "plt.plot(validation_loss[:], label='validation loss')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ea3b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %% get best models\n",
    "checkpoint = torch.load(BEST_MODEL1_PATH)\n",
    "model1 = depthmodel()\n",
    "model1 = model1.to(device)\n",
    "model1.load_state_dict(checkpoint)\n",
    "\n",
    "checkpoint = torch.load(BEST_MODEL2_PATH)\n",
    "model2 = depthmodel()\n",
    "model2 = model2.to(device)\n",
    "model2.load_state_dict(checkpoint)\n",
    "\n",
    "checkpoint = torch.load(BEST_MODEL3_PATH)\n",
    "model3 = depthmodel()\n",
    "model3 = model3.to(device)\n",
    "model3.load_state_dict(checkpoint)\n",
    "\n",
    "checkpoint = torch.load(BEST_MODEL4_PATH)\n",
    "model4 = depthmodel()\n",
    "model4 = model4.to(device)\n",
    "model4.load_state_dict(checkpoint)\n",
    "\n",
    "case_checkpoint = torch.load(CASE_BEST_MODEL_PATH)\n",
    "case_model = casemodel()\n",
    "case_model = case_model.to(device)\n",
    "case_model.load_state_dict(case_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d361f74",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %% submit\n",
    "inference(model1, model2, model3, model4, case_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd920a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %% summary\n",
    "\"\"\"\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(1, CFG['WIDTH'], CFG['HEIGHT']), device=device.type)\n",
    "\n",
    "print(model)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}